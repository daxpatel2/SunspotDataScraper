{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31565a-0a38-4f66-ac7c-81ebafc7a349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258c2ba4-12b9-4562-87e6-af936db81d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this list contatins the years where we want to gather the data\n",
    "list_of_years = ['1974', '1975', '1976', '1977', '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e652d38f-16e4-468d-8d61-4624904e25c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrive_data_normal_scrapping():\n",
    "    for year in list_of_years:\n",
    "        # URL to scrape\n",
    "        url = \"http://fenyi.solarobs.epss.hun-ren.hu/ftp/pub/DPD/data/DPD\" + year + \".txt\"\n",
    "        \n",
    "\n",
    "        # url = \"http://fenyi.solarobs.epss.hun-ren.hu/ftp/pub/DPD/additional/tilt_angle/tilt\" + year + \".txt\"\n",
    "\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Get the content of the response\n",
    "        content = response.text\n",
    "\n",
    "        # Split the content into lines\n",
    "        lines = content.splitlines()\n",
    "\n",
    "        # dictionary to store the values: Keys-> Group number = values->dates that they appear\n",
    "        group_dates = {}\n",
    "\n",
    "        # Process each line\n",
    "        for line in lines:\n",
    "            # Split the line into columns based on whitespace\n",
    "            columns = line.split()\n",
    "\n",
    "            if line.startswith('g'):\n",
    "                columns = line.split()\n",
    "\n",
    "            # delete the irrelevant data from the list like time(in hours minutes and second)\n",
    "            for idx,value in enumerate(columns):\n",
    "                if idx == 4:\n",
    "                    del columns[idx]\n",
    "                    del columns[idx]\n",
    "                    del columns[idx]\n",
    "\n",
    "            print(\" \".join(columns))\n",
    "            print()  # Print a newline for better readability\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8284c12-6571-42bc-ad0d-3eb9ae6a60d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_and_process_data(year):\n",
    "    \n",
    "    url = f\"http://fenyi.solarobs.epss.hun-ren.hu/ftp/pub/DPD/data/DPD{year}.txt\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        content = response.text\n",
    "        lines = content.splitlines()\n",
    "\n",
    "        group_dates = {}\n",
    "\n",
    "        for line in lines:\n",
    "            if line.startswith('g'):\n",
    "                columns = line.split()\n",
    "                \n",
    "                # Extract the group number (it's in the 7th position after removing whitespaces)\n",
    "                group_number = columns[7]\n",
    "                \n",
    "                try:\n",
    "                    int_conversion_of_group_number = int(group_number)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "                # Construct the date from the year, month, and day in the line\n",
    "                date_str = f\"{columns[1]}-{columns[2]}-{columns[3]}\"\n",
    "                date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "\n",
    "                # If the group number is not in the dictionary, add it with an empty list\n",
    "                if group_number not in group_dates:\n",
    "                    group_dates[group_number] = []\n",
    "\n",
    "                # Append the date to the list for this group number\n",
    "                group_dates[group_number].append(date_obj)\n",
    "                \n",
    "        last_two_months_groups = {group: dates for group, dates in group_dates.items() if any(d.month >= 11 for d in dates)}\n",
    "        \n",
    "        # Load data from the next year to check for overlaps\n",
    "        next_year = int(year) + 1\n",
    "        nextt_year = str(next_year)\n",
    "        \n",
    "        url_next_year = f\"http://fenyi.solarobs.epss.hun-ren.hu/ftp/pub/DPD/data/DPD{nextt_year}.txt\"\n",
    "        response_next_year = requests.get(url_next_year)\n",
    "        \n",
    "        if response_next_year.status_code == 200:\n",
    "            content_next_year = response_next_year.text\n",
    "            lines_next_year = content_next_year.splitlines()\n",
    "\n",
    "            for line in lines_next_year:\n",
    "                if line.startswith('g'):\n",
    "                    columns = line.split()\n",
    "                    group_number = columns[7]\n",
    "                    \n",
    "                    try:\n",
    "                        int_conversion_of_group_number = int(group_number)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "\n",
    "                    date_str = f\"{columns[1]}-{columns[2]}-{columns[3]}\"\n",
    "                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "                    \n",
    "                    # Only consider dates in January and February of the next year\n",
    "                    if date_obj.month <= 2 and group_number in last_two_months_groups:\n",
    "                        group_dates[group_number].append(date_obj)\n",
    "                        print(group_dates[group_number])\n",
    "                        \n",
    "        return group_dates\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        return 0\n",
    "\n",
    "def calculate_group_durations(group_dates):\n",
    "    group_durations = {}\n",
    "    \n",
    "    for group, dates in group_dates.items():\n",
    "        if dates:\n",
    "            # Find the duration between the first and last date\n",
    "            min_date = min(dates)\n",
    "            max_date = max(dates)\n",
    "            duration = (max_date - min_date).days + 1  # Including both start and end dates\n",
    "            \n",
    "            group_durations[group] = duration\n",
    "\n",
    "    return group_durations\n",
    "\n",
    "def find_avg_days_between_all_sunspots(year):\n",
    "    all_group_dates = {}\n",
    "    # list with all the sunspot groups and the date they appear\n",
    "    year_group_dates = retrieve_and_process_data(year)\n",
    "    if year_group_dates == 0:\n",
    "        print('exiting because retrive_and_process data returned an error')\n",
    "        return 0\n",
    "    all_group_dates.update(year_group_dates)\n",
    "    \n",
    "    # Calculate the durations for each group\n",
    "    group_durations = calculate_group_durations(all_group_dates)\n",
    "    \n",
    "    total_days = 0\n",
    "    total_spots = 0\n",
    "    for group, days in list(group_durations.items()):\n",
    "        total_days += int(days)\n",
    "        total_spots += 1\n",
    "    all_group_dates = {}\n",
    "    return total_days/total_spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "421d713a-9d13-4c55-acc4-41d28af686b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'511': [datetime.datetime(1974, 10, 25, 0, 0), datetime.datetime(1974, 10, 26, 0, 0), datetime.datetime(1974, 10, 27, 0, 0), datetime.datetime(1974, 10, 28, 0, 0), datetime.datetime(1974, 10, 29, 0, 0), datetime.datetime(1974, 10, 30, 0, 0), datetime.datetime(1974, 10, 31, 0, 0), datetime.datetime(1974, 11, 1, 0, 0), datetime.datetime(1974, 11, 2, 0, 0), datetime.datetime(1974, 11, 3, 0, 0), datetime.datetime(1974, 11, 4, 0, 0), datetime.datetime(1974, 11, 5, 0, 0)], '519': [datetime.datetime(1974, 11, 2, 0, 0), datetime.datetime(1974, 11, 3, 0, 0), datetime.datetime(1974, 11, 4, 0, 0), datetime.datetime(1974, 11, 5, 0, 0), datetime.datetime(1974, 11, 6, 0, 0), datetime.datetime(1974, 11, 7, 0, 0), datetime.datetime(1974, 11, 8, 0, 0)], '517': [datetime.datetime(1974, 11, 4, 0, 0), datetime.datetime(1974, 11, 5, 0, 0), datetime.datetime(1974, 11, 6, 0, 0), datetime.datetime(1974, 11, 7, 0, 0), datetime.datetime(1974, 11, 8, 0, 0), datetime.datetime(1974, 11, 9, 0, 0), datetime.datetime(1974, 11, 10, 0, 0), datetime.datetime(1974, 11, 11, 0, 0)], '518': [datetime.datetime(1974, 11, 4, 0, 0), datetime.datetime(1974, 11, 5, 0, 0)], '520': [datetime.datetime(1974, 11, 5, 0, 0)], '521': [datetime.datetime(1974, 11, 10, 0, 0), datetime.datetime(1974, 11, 11, 0, 0)], '522': [datetime.datetime(1974, 11, 10, 0, 0), datetime.datetime(1974, 11, 11, 0, 0), datetime.datetime(1974, 11, 12, 0, 0), datetime.datetime(1974, 11, 13, 0, 0), datetime.datetime(1974, 11, 14, 0, 0)], '523': [datetime.datetime(1974, 11, 11, 0, 0), datetime.datetime(1974, 11, 12, 0, 0), datetime.datetime(1974, 11, 13, 0, 0), datetime.datetime(1974, 11, 14, 0, 0)], '524': [datetime.datetime(1974, 11, 15, 0, 0), datetime.datetime(1974, 11, 16, 0, 0), datetime.datetime(1974, 11, 17, 0, 0), datetime.datetime(1974, 11, 18, 0, 0), datetime.datetime(1974, 11, 19, 0, 0), datetime.datetime(1974, 11, 20, 0, 0), datetime.datetime(1974, 11, 21, 0, 0), datetime.datetime(1974, 11, 22, 0, 0), datetime.datetime(1974, 11, 24, 0, 0), datetime.datetime(1974, 11, 25, 0, 0), datetime.datetime(1974, 11, 26, 0, 0), datetime.datetime(1974, 11, 27, 0, 0), datetime.datetime(1974, 11, 28, 0, 0)], '525': [datetime.datetime(1974, 11, 15, 0, 0), datetime.datetime(1974, 11, 16, 0, 0), datetime.datetime(1974, 11, 17, 0, 0)], '527': [datetime.datetime(1974, 11, 19, 0, 0), datetime.datetime(1974, 11, 20, 0, 0), datetime.datetime(1974, 11, 21, 0, 0), datetime.datetime(1974, 11, 22, 0, 0), datetime.datetime(1974, 11, 24, 0, 0), datetime.datetime(1974, 11, 25, 0, 0)], '528': [datetime.datetime(1974, 11, 20, 0, 0), datetime.datetime(1974, 11, 21, 0, 0), datetime.datetime(1974, 11, 22, 0, 0), datetime.datetime(1974, 11, 24, 0, 0), datetime.datetime(1974, 11, 25, 0, 0), datetime.datetime(1974, 11, 26, 0, 0), datetime.datetime(1974, 11, 27, 0, 0), datetime.datetime(1974, 11, 28, 0, 0), datetime.datetime(1974, 11, 29, 0, 0), datetime.datetime(1974, 11, 30, 0, 0)], '529': [datetime.datetime(1974, 11, 24, 0, 0), datetime.datetime(1974, 11, 25, 0, 0), datetime.datetime(1974, 11, 26, 0, 0), datetime.datetime(1974, 11, 27, 0, 0), datetime.datetime(1974, 11, 28, 0, 0), datetime.datetime(1974, 11, 29, 0, 0), datetime.datetime(1974, 11, 30, 0, 0)], '531': [datetime.datetime(1974, 12, 5, 0, 0), datetime.datetime(1974, 12, 6, 0, 0)], '534': [datetime.datetime(1974, 12, 10, 0, 0), datetime.datetime(1974, 12, 11, 0, 0), datetime.datetime(1974, 12, 12, 0, 0), datetime.datetime(1974, 12, 13, 0, 0), datetime.datetime(1974, 12, 14, 0, 0), datetime.datetime(1974, 12, 15, 0, 0), datetime.datetime(1974, 12, 16, 0, 0), datetime.datetime(1974, 12, 17, 0, 0), datetime.datetime(1974, 12, 18, 0, 0), datetime.datetime(1974, 12, 19, 0, 0)], '535': [datetime.datetime(1974, 12, 10, 0, 0), datetime.datetime(1974, 12, 11, 0, 0), datetime.datetime(1974, 12, 12, 0, 0), datetime.datetime(1974, 12, 13, 0, 0)], '536': [datetime.datetime(1974, 12, 12, 0, 0), datetime.datetime(1974, 12, 13, 0, 0), datetime.datetime(1974, 12, 14, 0, 0), datetime.datetime(1974, 12, 15, 0, 0), datetime.datetime(1974, 12, 16, 0, 0), datetime.datetime(1974, 12, 17, 0, 0), datetime.datetime(1974, 12, 18, 0, 0), datetime.datetime(1974, 12, 19, 0, 0), datetime.datetime(1974, 12, 20, 0, 0), datetime.datetime(1974, 12, 21, 0, 0), datetime.datetime(1974, 12, 22, 0, 0), datetime.datetime(1974, 12, 23, 0, 0), datetime.datetime(1974, 12, 24, 0, 0)], '539': [datetime.datetime(1974, 12, 18, 0, 0), datetime.datetime(1974, 12, 19, 0, 0), datetime.datetime(1974, 12, 20, 0, 0), datetime.datetime(1974, 12, 21, 0, 0), datetime.datetime(1974, 12, 22, 0, 0), datetime.datetime(1974, 12, 23, 0, 0), datetime.datetime(1974, 12, 24, 0, 0), datetime.datetime(1974, 12, 25, 0, 0), datetime.datetime(1974, 12, 26, 0, 0), datetime.datetime(1974, 12, 27, 0, 0), datetime.datetime(1974, 12, 28, 0, 0)], '540': [datetime.datetime(1974, 12, 19, 0, 0), datetime.datetime(1974, 12, 20, 0, 0)], '541': [datetime.datetime(1974, 12, 19, 0, 0), datetime.datetime(1974, 12, 20, 0, 0), datetime.datetime(1974, 12, 21, 0, 0), datetime.datetime(1974, 12, 22, 0, 0), datetime.datetime(1974, 12, 23, 0, 0)], '545': [datetime.datetime(1974, 12, 28, 0, 0), datetime.datetime(1974, 12, 29, 0, 0), datetime.datetime(1974, 12, 30, 0, 0), datetime.datetime(1974, 12, 31, 0, 0)], '546': [datetime.datetime(1974, 12, 29, 0, 0), datetime.datetime(1974, 12, 30, 0, 0), datetime.datetime(1974, 12, 31, 0, 0)], '547': [datetime.datetime(1974, 12, 31, 0, 0)]}\n",
      "546\n",
      "547\n",
      "546\n",
      "547\n",
      "546\n",
      "547\n",
      "546\n",
      "546\n",
      "546\n",
      "546\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_group_dates = {}\n",
    "\n",
    "# Retrieve and process data for each year\n",
    "year_group_dates = retrieve_and_process_data('1974')\n",
    "all_group_dates.update(year_group_dates)\n",
    "\n",
    "# Calculate the durations for each group\n",
    "group_durations = calculate_group_durations(all_group_dates)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(list(group_durations.items()), columns=['Group Number', 'Duration (Days)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce7e1b35-3648-4169-bc9b-dd266fe3d1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the year 1974 the average life span for a sunspot group was: 6.9209039548022595\n",
      "for the year 1975 the average life span for a sunspot group was: 6.153846153846154\n",
      "for the year 1976 the average life span for a sunspot group was: 7.166666666666667\n",
      "for the year 1977 the average life span for a sunspot group was: 6.158469945355192\n",
      "for the year 1978 the average life span for a sunspot group was: 7.283261802575107\n",
      "for the year 1979 the average life span for a sunspot group was: 7.794378698224852\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m list_of_average_sunspot_lifespan_per_year \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m list_of_years:\n\u001b[0;32m----> 3\u001b[0m     life_span_per_year \u001b[38;5;241m=\u001b[39m find_avg_days_between_all_sunspots(year)\n\u001b[1;32m      4\u001b[0m     list_of_average_sunspot_lifespan_per_year\u001b[38;5;241m.\u001b[39mappend(life_span_per_year)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the year \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m the average life span for a sunspot group was: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(year,life_span_per_year))\n",
      "Cell \u001b[0;32mIn[33], line 88\u001b[0m, in \u001b[0;36mfind_avg_days_between_all_sunspots\u001b[0;34m(year)\u001b[0m\n\u001b[1;32m     86\u001b[0m all_group_dates \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# list with all the sunspot groups and the date they appear\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m year_group_dates \u001b[38;5;241m=\u001b[39m retrieve_and_process_data(year)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m year_group_dates \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexiting because retrive_and_process data returned an error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[33], line 43\u001b[0m, in \u001b[0;36mretrieve_and_process_data\u001b[0;34m(year)\u001b[0m\n\u001b[1;32m     40\u001b[0m nextt_year \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(next_year)\n\u001b[1;32m     42\u001b[0m url_next_year \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://fenyi.solarobs.epss.hun-ren.hu/ftp/pub/DPD/data/DPD\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnextt_year\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 43\u001b[0m response_next_year \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url_next_year)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response_next_year\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     46\u001b[0m     content_next_year \u001b[38;5;241m=\u001b[39m response_next_year\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 747\u001b[0m     r\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(CONTENT_CHUNK_SIZE)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/response.py:624\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> 624\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content):\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m line\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/response.py:831\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 831\u001b[0m chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_chunk(amt)\n\u001b[1;32m    832\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[1;32m    833\u001b[0m     chunk, decode_content\u001b[38;5;241m=\u001b[39mdecode_content, flush_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    834\u001b[0m )\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/response.py:775\u001b[0m, in \u001b[0;36mHTTPResponse._handle_chunk\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m amt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left:\n\u001b[0;32m--> 775\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39m_safe_read(amt)\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m-\u001b[39m amt\n\u001b[1;32m    777\u001b[0m     returned_chunk \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:631\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[1;32m    625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_of_average_sunspot_lifespan_per_year = []\n",
    "for year in list_of_years:\n",
    "    life_span_per_year = find_avg_days_between_all_sunspots(year)\n",
    "    list_of_average_sunspot_lifespan_per_year.append(life_span_per_year)\n",
    "    print(\"for the year {} the average life span for a sunspot group was: {}\".format(year,life_span_per_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb3086-f873-4e80-93f8-8020467caee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(list_of_average_sunspot_lifespan_per_year, bins=10, edgecolor='black')\n",
    "plt.title('Histogram of Average Sunspot Group Lifespan')\n",
    "plt.xlabel('Average Lifespan (Days)')\n",
    "plt.ylabel('Years')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd49a3-ff77-4cb0-ba68-6a5e96567727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(list_of_years, list_of_average_sunspot_lifespan_per_year, marker='o', linestyle='-', color='b')\n",
    "plt.title('Average Sunspot Group Lifespan by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Lifespan (Days)')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
